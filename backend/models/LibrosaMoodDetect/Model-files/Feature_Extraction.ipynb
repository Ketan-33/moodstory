{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4521f0cc-ed10-46cb-8456-64326f265c17",
   "metadata": {},
   "source": [
    "# Solution Design - Feature Extraction\n",
    "\n",
    "For this task, the following features are extracted from the dataset\n",
    "> Mel (128) Features\n",
    "\n",
    "> MFCC (40) Features\n",
    "\n",
    "> Chroma(12) Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75fa69-c49a-4a05-85ef-7940eb5fd8b1",
   "metadata": {},
   "source": [
    "## Environment Creation\n",
    "(Kindly ignore if already performed)\n",
    "* The code is designed to run in Intel DevCloud Jupyter Notebook environment which comes with predefined conda environments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c2a866-3bc1-4f43-a464-8e8f822ea455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:      /glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/latest/envs/tensorflow\n",
      "Destination: /home/u94139/.conda/envs/ser\n",
      "Packages: 181\n",
      "Files: 5328\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate ser\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# Cloning the existing Intel AI Analytics Toolkit Tensorflow environment\n",
    "! conda create --name ser --clone tensorflow\n",
    "\n",
    "# Activating the new virtual environment\n",
    "! source activate ser\n",
    "\n",
    "# Installing Python's Audio Processing Library LibROSA\n",
    "\n",
    "# Upgrading NumPy to latest version to avoid conflicts\n",
    "! pip install --user --upgrade numpy\n",
    "\n",
    "# Installing LibROSA and checking version\n",
    "! pip install --user librosa --force-reinstall\n",
    "! python -c 'import librosa; print(librosa.__version__)'\n",
    "\n",
    "# Installing the package plotly\n",
    "! pip install --user plotly\n",
    "\n",
    "# Creating a IPython kernel using the new conda environment\n",
    "! python -m ipykernel install --user --name=ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5b592e-c16d-4bbb-a0ac-e9e00b6d6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries for dataset processing and feature extraction\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import plotly.offline as py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a1018-01e4-4b24-95ca-d01be8e78821",
   "metadata": {},
   "source": [
    "Once LibROSA is installed, load the required libraries for performing feature extraction by running the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b178ed0c-d599-4e88-afaa-6ebf164df449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Settings\n",
    "\n",
    "# Supress Warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Display all columns of the dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9621bd-3a31-40f7-b4ce-39da021f4132",
   "metadata": {},
   "source": [
    "### Loading Dataset and Extraction Emotion and Gender from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac99ba03-df95-431e-bab0-488357367745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset and extracting information from the filename\n",
    "\n",
    "# Loading Data\n",
    "def labeler(base_dir_path):\n",
    "    dir_list = os.listdir(base_dir_path)\n",
    "    dir_list.sort()\n",
    "\n",
    "    # RAVDESS dataset format\n",
    "    df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender', 'intensity', 'statement', 'repetition', 'emotion'])\n",
    "    count = 0\n",
    "\n",
    "    # Extracting information from filename\n",
    "    for file in os.listdir(base_dir_path):\n",
    "        filename = file.split('.')[0].split('-')\n",
    "        if(len(filename)==7):\n",
    "            path = base_dir_path + file\n",
    "            src = int(filename[1])\n",
    "            actor = int(filename[-1])\n",
    "            emotion = int(filename[2])\n",
    "            if int(actor)%2 == 0:\n",
    "                gender = \"female\"\n",
    "            else:\n",
    "                gender = \"male\"\n",
    "\n",
    "            if filename[3] == '01':\n",
    "                intensity = 0\n",
    "            else:\n",
    "                intensity = 1\n",
    "\n",
    "            if filename[4] == '01':\n",
    "                statement = 0\n",
    "            else:\n",
    "                statement = 1\n",
    "\n",
    "            if filename[5] == '01':\n",
    "                repeat = 0\n",
    "            else:\n",
    "                repeat = 1\n",
    "\n",
    "        df.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
    "        count += 1\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if df.emotion[i] == 1:\n",
    "            label = \"_neutral\"\n",
    "        elif df.emotion[i] == 2:\n",
    "            label = \"_calm\"\n",
    "        elif df.emotion[i] == 3:\n",
    "            label = \"_happy\"\n",
    "        elif df.emotion[i] == 4:\n",
    "            label = \"_sad\"\n",
    "        elif df.emotion[i] == 5:\n",
    "            label = \"_angry\"\n",
    "        elif df.emotion[i] == 6:\n",
    "            label = \"_fearful\"\n",
    "        elif df.emotion[i] == 7:\n",
    "            label = \"_disgust\"\n",
    "        elif df.emotion[i] == 8:\n",
    "            label = \"_surprised\"\n",
    "        else:\n",
    "            label = \"_none\"\n",
    "\n",
    "        # Add gender to the label \n",
    "        labels.append(df.loc[i,'gender'] + label)\n",
    "\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32338b63-a68c-498b-a2cd-b86ec285b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the labeler function\n",
    "df = labeler(\"./DATASET/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c2030a-d6bb-4983-b1e0-297a0b6ac200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>actor</th>\n",
       "      <th>gender</th>\n",
       "      <th>intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./DATASET/03-02-05-01-02-01-05.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./DATASET/77-52-03-11-51-62-25.wav</td>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./DATASET/03-01-04-01-01-01-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./DATASET/16-93-07-69-25-53-25.wav</td>\n",
       "      <td>93</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>male_disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./DATASET/24-77-01-74-45-69-25.wav</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>./DATASET/03-02-03-01-02-01-07.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>./DATASET/53-55-06-62-98-35-26.wav</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>./DATASET/03-01-04-02-02-02-22.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>./DATASET/53-33-03-90-81-83-25.wav</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>./DATASET/39-60-05-89-50-78-25.wav</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5252 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    path  source  actor  gender  intensity  \\\n",
       "0     ./DATASET/03-02-05-01-02-01-05.wav       2      5    male          0   \n",
       "1     ./DATASET/77-52-03-11-51-62-25.wav      52     25    male          1   \n",
       "2     ./DATASET/03-01-04-01-01-01-14.wav       1     14  female          0   \n",
       "3     ./DATASET/16-93-07-69-25-53-25.wav      93     25    male          1   \n",
       "4     ./DATASET/24-77-01-74-45-69-25.wav      77     25    male          1   \n",
       "...                                  ...     ...    ...     ...        ...   \n",
       "5247  ./DATASET/03-02-03-01-02-01-07.wav       2      7    male          0   \n",
       "5248  ./DATASET/53-55-06-62-98-35-26.wav      55     26  female          1   \n",
       "5249  ./DATASET/03-01-04-02-02-02-22.wav       1     22  female          1   \n",
       "5250  ./DATASET/53-33-03-90-81-83-25.wav      33     25    male          1   \n",
       "5251  ./DATASET/39-60-05-89-50-78-25.wav      60     25    male          1   \n",
       "\n",
       "      statement  repetition  emotion           label  \n",
       "0             1           0        5      male_angry  \n",
       "1             1           1        3      male_happy  \n",
       "2             0           0        4      female_sad  \n",
       "3             1           1        7    male_disgust  \n",
       "4             1           1        1    male_neutral  \n",
       "...         ...         ...      ...             ...  \n",
       "5247          1           0        3      male_happy  \n",
       "5248          1           1        6  female_fearful  \n",
       "5249          1           1        4      female_sad  \n",
       "5250          1           1        3      male_happy  \n",
       "5251          1           1        5      male_angry  \n",
       "\n",
       "[5252 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9adcb4-60fd-4867-8da3-59b4ba30ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified splitting into train and test sets\n",
    "# Test size is 0.2\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=2, random_state=11, test_size=0.2)\n",
    "for train_index, test_index in sss.split(df, df.label):\n",
    "    df_train, df_test = df.iloc[train_index,:], df.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1830276-4d9b-40ec-87ff-66b028a36daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Replace index of file with path to extract features from location\n",
    "\n",
    "df_train.index = df_train.path\n",
    "df_train = df_train.drop(\"path\", axis=1)\n",
    "\n",
    "\n",
    "df_test.index = df_test.path\n",
    "df_test = df_test.drop(\"path\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e56cb-489f-4ce9-bd4b-2e36e604aa4e",
   "metadata": {},
   "source": [
    "### Performing Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25d744a-6618-42be-bb85-27e2e964ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features such as MFCC, Mels and Chromas from audio\n",
    "\n",
    "def extract_features(df):\n",
    "    # features store all features extracted from the audio file\n",
    "    # labels is the labels for the audio file\n",
    "    # names is the name of the audio file\n",
    "    features = pd.DataFrame(columns=['feature'])\n",
    "    labels = pd.DataFrame(columns=['label'])\n",
    "    names = pd.DataFrame(columns=['name'])\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        x, sample_rate = librosa.load(df.index[i])\n",
    "        \n",
    "        # feature_set stores all features of the audio file\n",
    "        feature_set = np.array([])\n",
    "        \n",
    "        # MFCC feature extraction\n",
    "        # No. of MFCC Features = 40 (Default = 20)\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        feature_set=np.hstack((feature_set, mfccs))\n",
    "        \n",
    "        ## Chroma feature extraction\n",
    "        # No. of Chroma Features = 12 (Always)\n",
    "        stft=np.abs(librosa.stft(x))\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        feature_set=np.hstack((feature_set, chroma))\n",
    "        \n",
    "        ## Mel feature extraction\n",
    "        # No. of Mel Features = 128 (Default = 128)\n",
    "        mel=np.mean(librosa.feature.melspectrogram(x, sr=sample_rate).T,axis=0)\n",
    "        feature_set=np.hstack((feature_set, mel))\n",
    "        \n",
    "        # Total features = MFCC(40) + Chroma(12) + Mels(128) = 180\n",
    "        labels.at[i, 'label'] = df.iloc[i, df.columns.get_loc('label')]\n",
    "        features.loc[i] = [feature_set]\n",
    "        names.at[i,'name'] = df.index[i].split('/')[-1]\n",
    "        \n",
    "        \n",
    "    final_data = pd.DataFrame(features['feature'].values.tolist())\n",
    "    final_data = pd.concat([final_data,labels,names], axis=1)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730f77fa-3e13-4d6d-8182-718f76b9637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4201/4201 [11:59<00:00,  5.84it/s]\n",
      "100%|██████████| 1051/1051 [02:49<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract features from the audio files\n",
    "# Note: This wil take some time since feature extraction is done from 5252 audio files\n",
    "\n",
    "train_data = extract_features(df_train)\n",
    "test_data = extract_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c684c3c2-b107-459e-a16e-6834cd337c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4201, 182)\n",
      "(1051, 182)\n"
     ]
    }
   ],
   "source": [
    "# Prining the shape of the extracted feature set\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd68d362-ae18-4cd5-9ddc-246de6f725f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the features as CSV for easily executing and experimenting\n",
    "\n",
    "train_data.to_csv(\"train_features.csv\", index=False)\n",
    "test_data.to_csv(\"test_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0ee3e-9ef1-4d45-8949-1faf3a094978",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### END OF NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a64892-efcb-430e-a5ac-1585d071aa2d",
   "metadata": {},
   "source": [
    "#### _Citations_\n",
    "\n",
    "###### Audio Features\n",
    "* https://towardsdatascience.com/how-i-understood-what-features-to-consider-while-training-audio-files-eedfb6e9002b\n",
    "* https://www.codespeedy.com/speech-emotion-recognition-in-python/\n",
    "\n",
    "###### Base Paper\n",
    "* http://www.ijasret.com/VolumeArticles/FullTextPDF/830_34.SPEECH_BASED_EMOTION_RECOGNITION.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d81ea-1c28-475d-b117-d39ec54c0ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
