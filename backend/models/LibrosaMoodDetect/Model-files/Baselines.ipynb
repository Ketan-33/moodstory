{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Hyper-Parameter Tuned Baseline Classifiers for Benchmark\n",
    "\n",
    "\n",
    "### Features Extracted [Mel(128), MFCC(40), Chroma(12)]\n",
    "### Gender Splitted\n",
    "### Hyper-Parameter Tuning\n",
    "### Classical Classifiers and Voting Classifiers\n",
    "\n",
    "* This notebook extracts audio features and considers the following nine baseline classifiers which will serve as a benchmark for the proposed model\n",
    "1. Light Gradient Boosing Machine\n",
    "2. Random Forest\n",
    "3. eXtreme Gradient Boosting\n",
    "3. Multi-Layer Perceptron\n",
    "4. K-Nearest Neighbor\n",
    "5. Decision Tree\n",
    "6. Logistic Regression\n",
    "* The notebook also combines the best of classifiers and creates four new classifiers which is a combination of best of the above classifiers\n",
    "7. V1 [Multi-Layer Perceptron, Light Gradient Boosing Machine]\n",
    "8. V2 [K-Nearest Neighbor, eXtreme Gradient Boosting, Multi-Layer Perceptron]\n",
    "9. V3 [eXtreme Gradient Boosting, Multi-Layer Perceptron, Random Forest, Logistic Regression]\n",
    "10. V4 [Multi-Layer Perceptron, eXtreme Gradient Boosting]\n",
    "\n",
    "* The hyper-parementer tuning is performed using Optune Framework (https://optuna.org/) to get the best parameters for the baseline classifiers\n",
    "* The baseline classifiers are cross-validated and the classification report and confusion matrix is displayed\n",
    "\n",
    "##### __IMPORTANT NOTE: This notebook is \"extremely\" CPU intensive and can several hours to complete.__\n",
    "Approximated Runtimes on Intel DevCloud Jupyter Notebook Node\n",
    "* Feature Extraction: 15 minutes\n",
    "* Hyper-Parameter Tuning: 4 Hours + \n",
    "* Training Tuned Classifiers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/u94139/.local/lib/python3.9/site-packages (3.0.5)\n",
      "Requirement already satisfied: tqdm in /glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (22.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (4.11.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (1.4.27)\n",
      "Requirement already satisfied: cliff in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (4.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (1.7.7)\n",
      "Requirement already satisfied: colorlog in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: PyYAML in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: numpy in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/u94139/.local/lib/python3.9/site-packages (from optuna) (0.9.0)\n",
      "Requirement already satisfied: Mako in /home/u94139/.local/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/u94139/.local/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna) (3.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/u94139/.local/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/u94139/.local/lib/python3.9/site-packages (from cliff->optuna) (4.1.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/u94139/.local/lib/python3.9/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/u94139/.local/lib/python3.9/site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/u94139/.local/lib/python3.9/site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/u94139/.local/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/u94139/.local/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/u94139/.local/lib/python3.9/site-packages (from stevedore>=2.0.1->cliff->optuna) (5.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/u94139/.local/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: lightgbm in /home/u94139/.local/lib/python3.9/site-packages (3.3.3)\n",
      "Requirement already satisfied: numpy in /home/u94139/.local/lib/python3.9/site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in /home/u94139/.local/lib/python3.9/site-packages (from lightgbm) (1.8.1)\n",
      "Requirement already satisfied: wheel in /glob/development-tools/versions/oneapi/2023.0/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/u94139/.local/lib/python3.9/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/u94139/.local/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/u94139/.local/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Activating ser conda environment\n",
    "! source activate ser\n",
    "\n",
    "# Installing the Optune Framework package for Hyper-Paramenter Tuning\n",
    "! pip install --user optuna\n",
    "\n",
    "# Installing other classifier packages\n",
    "! pip install --user lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Settings\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob \n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract audio features\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    result=np.hstack((result, mfccs))\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, chroma))\n",
    "    mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Classes and Gender\n",
    "\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "def gender(g):\n",
    "    \"\"\"Returns Gender Label\"\"\"\n",
    "    if int(g[0:2]) % 2 == 0:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    \"\"\"Loads Data from directory containing WAV files.\"\"\"\n",
    "    x,y=[],[]\n",
    "    for file in tqdm(glob.glob(\"./DATASET/*.wav\")): # Path to audio dataset\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]] + '_' + gender(file_name.split(\"-\")[-1])\n",
    "        feature=extract_feature(file)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5252/5252 [12:53<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4201, 1051)\n",
      "(180, 180)\n",
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape[0], X_test.shape[0]))\n",
    "print((X_train.shape[1], X_test.shape[1]))\n",
    "print(f'Features extracted: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER-PARAMETER TUNING USING OPTUNA FRAMEWORK (OPTIONAL)\n",
    "\n",
    "N.B.: If hyper-parameters are obtained, copy them and paste it into the corrosponding model parameters below and do not run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb(trial): \n",
    "\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 20000),\n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 100000, 500000),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 500),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 100),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.0, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-0),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss','gbdt','dart']),\n",
    "        'objective': 'multiclass',\n",
    "        'verbose': -1,\n",
    "        'random_state':22,\n",
    "        }\n",
    "   \n",
    "    model = lgb.LGBMClassifier(**params, n_jobs = 12) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 12:40:49,820]\u001b[0m A new study created in memory with name: no-name-2b577db4-2701-456e-9182-9adf236a1f39\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=467, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=467\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=467, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=467\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=467, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=467\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=467, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=467\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=467, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 12:42:16,093]\u001b[0m Trial 0 finished with value: 0.7307748711850971 and parameters: {'num_leaves': 15, 'max_depth': 18, 'n_estimators': 9423, 'subsample_for_bin': 177318, 'min_data_in_leaf': 467, 'reg_alpha': 21.364324863046125, 'colsample_bytree': 0.4166169833515284, 'learning_rate': 0.08988880633472562, 'boosting_type': 'gbdt'}. Best is trial 0 with value: 0.7307748711850971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 12:45:58,324]\u001b[0m Trial 1 finished with value: 0.659364135666157 and parameters: {'num_leaves': 8, 'max_depth': 98, 'n_estimators': 12899, 'subsample_for_bin': 269886, 'min_data_in_leaf': 439, 'reg_alpha': 12.73644948176721, 'colsample_bytree': 0.18931542811418567, 'learning_rate': 7.905719250121463e-05, 'boosting_type': 'goss'}. Best is trial 0 with value: 0.7307748711850971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=226, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=226\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=226, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=226\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=226, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=226\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=226, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=226\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=226, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 12:56:06,153]\u001b[0m Trial 2 finished with value: 0.48866655342279597 and parameters: {'num_leaves': 31, 'max_depth': 47, 'n_estimators': 8085, 'subsample_for_bin': 188423, 'min_data_in_leaf': 226, 'reg_alpha': 70.66238836396343, 'colsample_bytree': 0.3381317494631866, 'learning_rate': 0.006727407881920793, 'boosting_type': 'dart'}. Best is trial 0 with value: 0.7307748711850971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:00:21,979]\u001b[0m Trial 3 finished with value: 0.06284157182492497 and parameters: {'num_leaves': 139, 'max_depth': 32, 'n_estimators': 17808, 'subsample_for_bin': 235415, 'min_data_in_leaf': 307, 'reg_alpha': 98.2433944932535, 'colsample_bytree': 0.40150552585613264, 'learning_rate': 0.543254952678558, 'boosting_type': 'dart'}. Best is trial 0 with value: 0.7307748711850971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:04:37,909]\u001b[0m Trial 4 finished with value: 0.45941056565313404 and parameters: {'num_leaves': 108, 'max_depth': 89, 'n_estimators': 12949, 'subsample_for_bin': 332299, 'min_data_in_leaf': 147, 'reg_alpha': 89.00759212637116, 'colsample_bytree': 0.6679200653814781, 'learning_rate': 0.00021282819246622793, 'boosting_type': 'goss'}. Best is trial 0 with value: 0.7307748711850971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:10:31,604]\u001b[0m Trial 5 finished with value: 0.7517213068342676 and parameters: {'num_leaves': 22, 'max_depth': 100, 'n_estimators': 16025, 'subsample_for_bin': 118611, 'min_data_in_leaf': 134, 'reg_alpha': 31.920033893710244, 'colsample_bytree': 0.9982880803922601, 'learning_rate': 0.00047686959240402714, 'boosting_type': 'goss'}. Best is trial 5 with value: 0.7517213068342676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=437, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=437\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=437, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=437\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=437, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=437\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=437, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=437\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=437, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:14:20,658]\u001b[0m Trial 6 finished with value: 0.697210237245909 and parameters: {'num_leaves': 4, 'max_depth': 47, 'n_estimators': 3958, 'subsample_for_bin': 444732, 'min_data_in_leaf': 437, 'reg_alpha': 35.91188580520871, 'colsample_bytree': 0.3243961538846868, 'learning_rate': 0.13263740946272637, 'boosting_type': 'dart'}. Best is trial 5 with value: 0.7517213068342676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=447, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=447, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=447, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=447, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=447\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=447, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:15:13,499]\u001b[0m Trial 7 finished with value: 0.6531767736821243 and parameters: {'num_leaves': 94, 'max_depth': 33, 'n_estimators': 4612, 'subsample_for_bin': 423782, 'min_data_in_leaf': 447, 'reg_alpha': 60.478215204706906, 'colsample_bytree': 0.8356119642020825, 'learning_rate': 0.0021486099484051223, 'boosting_type': 'goss'}. Best is trial 5 with value: 0.7517213068342676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=451, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=451\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=451, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=451\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=451, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=451\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=451, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=451\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=451, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 13:46:21,352]\u001b[0m Trial 8 finished with value: 0.7567193250665307 and parameters: {'num_leaves': 76, 'max_depth': 17, 'n_estimators': 18599, 'subsample_for_bin': 165047, 'min_data_in_leaf': 451, 'reg_alpha': 16.916634984956957, 'colsample_bytree': 0.8881241087894987, 'learning_rate': 0.0017525101066842008, 'boosting_type': 'dart'}. Best is trial 8 with value: 0.7567193250665307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=480, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=480\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=480, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=480\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=480, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=480\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=480, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=480\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=480, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 14:10:29,888]\u001b[0m Trial 9 finished with value: 0.20757601494819095 and parameters: {'num_leaves': 71, 'max_depth': 78, 'n_estimators': 18315, 'subsample_for_bin': 275076, 'min_data_in_leaf': 480, 'reg_alpha': 79.8540162128086, 'colsample_bytree': 0.49958544080983003, 'learning_rate': 0.00010571493509114321, 'boosting_type': 'dart'}. Best is trial 8 with value: 0.7567193250665307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=326, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=326\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=326, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=326\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=326, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=326\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=326, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=326\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=326, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 14:10:33,809]\u001b[0m Trial 10 finished with value: 0.07902893380895759 and parameters: {'num_leaves': 52, 'max_depth': 4, 'n_estimators': 104, 'subsample_for_bin': 101437, 'min_data_in_leaf': 326, 'reg_alpha': 3.6561992833743737, 'colsample_bytree': 0.7301059168542271, 'learning_rate': 1.4490514053156924e-05, 'boosting_type': 'gbdt'}. Best is trial 8 with value: 0.7567193250665307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 14:14:09,510]\u001b[0m Trial 11 finished with value: 0.7812400203838967 and parameters: {'num_leaves': 44, 'max_depth': 67, 'n_estimators': 15500, 'subsample_for_bin': 102097, 'min_data_in_leaf': 14, 'reg_alpha': 35.274734370320914, 'colsample_bytree': 0.9765873416449043, 'learning_rate': 0.0040789319240881585, 'boosting_type': 'goss'}. Best is trial 11 with value: 0.7812400203838967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 14:55:41,632]\u001b[0m Trial 12 finished with value: 0.677452296019478 and parameters: {'num_leaves': 55, 'max_depth': 69, 'n_estimators': 19768, 'subsample_for_bin': 162644, 'min_data_in_leaf': 17, 'reg_alpha': 45.95935259569694, 'colsample_bytree': 0.9249969670146562, 'learning_rate': 0.005736119288180306, 'boosting_type': 'dart'}. Best is trial 11 with value: 0.7812400203838967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 14:57:58,880]\u001b[0m Trial 13 finished with value: 0.7998063529811448 and parameters: {'num_leaves': 86, 'max_depth': 66, 'n_estimators': 14299, 'subsample_for_bin': 365574, 'min_data_in_leaf': 32, 'reg_alpha': 24.88685277750192, 'colsample_bytree': 0.6713127954205013, 'learning_rate': 0.023360346645062598, 'boosting_type': 'goss'}. Best is trial 13 with value: 0.7998063529811448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:00:07,597]\u001b[0m Trial 14 finished with value: 0.7726700073608516 and parameters: {'num_leaves': 108, 'max_depth': 63, 'n_estimators': 13906, 'subsample_for_bin': 353868, 'min_data_in_leaf': 10, 'reg_alpha': 48.03904012707117, 'colsample_bytree': 0.6663820088091268, 'learning_rate': 0.02844146530352623, 'boosting_type': 'goss'}. Best is trial 13 with value: 0.7998063529811448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=82, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:02:41,623]\u001b[0m Trial 15 finished with value: 0.7862377555064832 and parameters: {'num_leaves': 143, 'max_depth': 61, 'n_estimators': 15280, 'subsample_for_bin': 398277, 'min_data_in_leaf': 82, 'reg_alpha': 30.91448798543, 'colsample_bytree': 0.774572818049516, 'learning_rate': 0.018695718794815804, 'boosting_type': 'goss'}. Best is trial 13 with value: 0.7998063529811448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:04:22,103]\u001b[0m Trial 16 finished with value: 0.8045662759753128 and parameters: {'num_leaves': 147, 'max_depth': 57, 'n_estimators': 11073, 'subsample_for_bin': 488937, 'min_data_in_leaf': 91, 'reg_alpha': 23.978509061538183, 'colsample_bytree': 0.5886725151170362, 'learning_rate': 0.03200080792487808, 'boosting_type': 'goss'}. Best is trial 16 with value: 0.8045662759753128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:06:20,833]\u001b[0m Trial 17 finished with value: 0.13591444425570468 and parameters: {'num_leaves': 123, 'max_depth': 79, 'n_estimators': 11277, 'subsample_for_bin': 479905, 'min_data_in_leaf': 92, 'reg_alpha': 1.658602164862998, 'colsample_bytree': 0.5742498084893155, 'learning_rate': 0.6471267655375141, 'boosting_type': 'goss'}. Best is trial 16 with value: 0.8045662759753128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:06:56,870]\u001b[0m Trial 18 finished with value: 0.5160571315327558 and parameters: {'num_leaves': 124, 'max_depth': 49, 'n_estimators': 6966, 'subsample_for_bin': 499339, 'min_data_in_leaf': 204, 'reg_alpha': 58.77656324352118, 'colsample_bytree': 0.08289038605843829, 'learning_rate': 0.07522253393181473, 'boosting_type': 'gbdt'}. Best is trial 16 with value: 0.8045662759753128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:08:34,924]\u001b[0m Trial 19 finished with value: 0.7979018741860596 and parameters: {'num_leaves': 150, 'max_depth': 37, 'n_estimators': 10970, 'subsample_for_bin': 372244, 'min_data_in_leaf': 80, 'reg_alpha': 25.29437378449422, 'colsample_bytree': 0.5714174883183664, 'learning_rate': 0.030555080414197758, 'boosting_type': 'goss'}. Best is trial 16 with value: 0.8045662759753128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:09:24,352]\u001b[0m Trial 20 finished with value: 0.8131345903402979 and parameters: {'num_leaves': 90, 'max_depth': 57, 'n_estimators': 6416, 'subsample_for_bin': 449062, 'min_data_in_leaf': 170, 'reg_alpha': 12.790778368648716, 'colsample_bytree': 0.5660043664435338, 'learning_rate': 0.27645578068240395, 'boosting_type': 'goss'}. Best is trial 20 with value: 0.8131345903402979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:10:06,813]\u001b[0m Trial 21 finished with value: 0.8155149765018969 and parameters: {'num_leaves': 93, 'max_depth': 57, 'n_estimators': 5183, 'subsample_for_bin': 451907, 'min_data_in_leaf': 164, 'reg_alpha': 11.212768670906843, 'colsample_bytree': 0.5871650483185199, 'learning_rate': 0.19989208497950994, 'boosting_type': 'goss'}. Best is trial 21 with value: 0.8155149765018969.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:10:48,396]\u001b[0m Trial 22 finished with value: 0.8167077175697866 and parameters: {'num_leaves': 102, 'max_depth': 55, 'n_estimators': 5239, 'subsample_for_bin': 451297, 'min_data_in_leaf': 179, 'reg_alpha': 10.166085786278504, 'colsample_bytree': 0.5564115021925584, 'learning_rate': 0.23410649113166168, 'boosting_type': 'goss'}. Best is trial 22 with value: 0.8167077175697866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=171, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:11:21,823]\u001b[0m Trial 23 finished with value: 0.8112335088613328 and parameters: {'num_leaves': 99, 'max_depth': 54, 'n_estimators': 4439, 'subsample_for_bin': 449828, 'min_data_in_leaf': 171, 'reg_alpha': 10.298161147968209, 'colsample_bytree': 0.4732585790389039, 'learning_rate': 0.22318569716533146, 'boosting_type': 'goss'}. Best is trial 22 with value: 0.8167077175697866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=282, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=282\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=282, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=282\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=282, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=282\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=282, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=282\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=282, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 15:11:32,441]\u001b[0m Trial 24 finished with value: 0.32983353151010697 and parameters: {'num_leaves': 63, 'max_depth': 40, 'n_estimators': 1674, 'subsample_for_bin': 410277, 'min_data_in_leaf': 282, 'reg_alpha': 5.822028287321087, 'colsample_bytree': 0.24351807574820955, 'learning_rate': 0.9590454530172389, 'boosting_type': 'goss'}. Best is trial 22 with value: 0.8167077175697866.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_lgb, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    \n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 25),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 15000, 25000),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 5),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 25),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 50, 250),\n",
    "        }\n",
    "   \n",
    "    model = RandomForestClassifier(**params, random_state = 22) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-29 00:44:47,370]\u001b[0m A new study created in memory with name: no-name-72c7325e-1c5e-4c94-b8ae-e3c303489eb7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_rf, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "\n",
    "    param = {\n",
    "        'silent': 1,\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 16,\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0)\n",
    "    }\n",
    "\n",
    "    if param['booster'] == 'gbtree' or param['booster'] == 'gblinear':\n",
    "        param['max_depth'] = trial.suggest_int('max_depth', 1, 9)\n",
    "        param['eta'] = trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
    "        param['gamma'] = trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
    "        param['grow_policy'] = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\n",
    "    if param['booster'] == 'dart':\n",
    "        param['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])\n",
    "        param['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree', 'forest'])\n",
    "        param['rate_drop'] = trial.suggest_loguniform('rate_drop', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "  \n",
    "    model = xgb.XGBClassifier() \n",
    "    \n",
    "    model.set_params(**param)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_xgb, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial):\n",
    "\n",
    "    params = {\n",
    "        'activation': trial.suggest_categorical('activation', ['logistic', 'tanh', 'relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "        'hidden_layer_sizes':trial.suggest_int('hidden_layer_sizes', 100, 1500),\n",
    "        'alpha': trial.suggest_uniform('alpha', 0.001, 0.99),\n",
    "        'batch_size':trial.suggest_int('batch_size', 150, 300), \n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', ['adaptive', 'constant', 'invscaling']),\n",
    "        'max_iter': 1000\n",
    "        }\n",
    "  \n",
    "    model = MLPClassifier(**params, random_state = 22) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 18:31:35,583]\u001b[0m A new study created in memory with name: no-name-bba9d8bb-d87f-4926-b67d-f6617224f1a7\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:35:19,671]\u001b[0m Trial 0 finished with value: 0.7272133514523527 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'hidden_layer_sizes': 272, 'alpha': 0.6655292519385918, 'batch_size': 249, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.7272133514523527.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:35:49,600]\u001b[0m Trial 1 finished with value: 0.807188437800804 and parameters: {'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 166, 'alpha': 0.721368233089467, 'batch_size': 151, 'learning_rate': 'adaptive'}. Best is trial 1 with value: 0.807188437800804.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:36:47,642]\u001b[0m Trial 2 finished with value: 0.30560330672102376 and parameters: {'activation': 'relu', 'solver': 'sgd', 'hidden_layer_sizes': 129, 'alpha': 0.3024295887507661, 'batch_size': 166, 'learning_rate': 'adaptive'}. Best is trial 1 with value: 0.807188437800804.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:37:42,417]\u001b[0m Trial 3 finished with value: 0.8693157239114434 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 377, 'alpha': 0.1733994351214348, 'batch_size': 282, 'learning_rate': 'constant'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:38:23,257]\u001b[0m Trial 4 finished with value: 0.28878659192571204 and parameters: {'activation': 'relu', 'solver': 'sgd', 'hidden_layer_sizes': 154, 'alpha': 0.3876747174156247, 'batch_size': 252, 'learning_rate': 'adaptive'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:41:23,228]\u001b[0m Trial 5 finished with value: 0.7388686937319517 and parameters: {'activation': 'relu', 'solver': 'sgd', 'hidden_layer_sizes': 746, 'alpha': 0.33970822571977854, 'batch_size': 154, 'learning_rate': 'adaptive'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:43:55,565]\u001b[0m Trial 6 finished with value: 0.7617289507955383 and parameters: {'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 308, 'alpha': 0.8498018562365101, 'batch_size': 190, 'learning_rate': 'adaptive'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:51:24,390]\u001b[0m Trial 7 finished with value: 0.7814826453768189 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'hidden_layer_sizes': 564, 'alpha': 0.9671941397873671, 'batch_size': 167, 'learning_rate': 'constant'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:58:51,982]\u001b[0m Trial 8 finished with value: 0.7602927354056962 and parameters: {'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 347, 'alpha': 0.014308419144147377, 'batch_size': 218, 'learning_rate': 'constant'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 18:59:27,664]\u001b[0m Trial 9 finished with value: 0.6715030292735404 and parameters: {'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': 803, 'alpha': 0.5647836919059182, 'batch_size': 268, 'learning_rate': 'constant'}. Best is trial 3 with value: 0.8693157239114434.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:02:06,148]\u001b[0m Trial 10 finished with value: 0.8855022365664459 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1345, 'alpha': 0.03656517228392153, 'batch_size': 295, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 0.8855022365664459.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:05:15,943]\u001b[0m Trial 11 finished with value: 0.8843126097049998 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1386, 'alpha': 0.00888472026956344, 'batch_size': 295, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 0.8855022365664459.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:08:31,982]\u001b[0m Trial 12 finished with value: 0.8902652737670573 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1442, 'alpha': 0.0027099149530944583, 'batch_size': 298, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:10:34,138]\u001b[0m Trial 13 finished with value: 0.8757445784496912 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1478, 'alpha': 0.15411679355865837, 'batch_size': 300, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:12:21,612]\u001b[0m Trial 14 finished with value: 0.8788381178868694 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1252, 'alpha': 0.15417733175995785, 'batch_size': 225, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:14:05,746]\u001b[0m Trial 15 finished with value: 0.8745560840269521 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1110, 'alpha': 0.22557574475179373, 'batch_size': 271, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:15:24,691]\u001b[0m Trial 16 finished with value: 0.869555234697922 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1045, 'alpha': 0.47196668013387544, 'batch_size': 251, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:18:05,319]\u001b[0m Trial 17 finished with value: 0.8845509880527717 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1248, 'alpha': 0.005049370589632294, 'batch_size': 276, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:20:05,542]\u001b[0m Trial 18 finished with value: 0.8607423135722779 and parameters: {'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 952, 'alpha': 0.10441055043640497, 'batch_size': 195, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:21:02,965]\u001b[0m Trial 19 finished with value: 0.81004190023215 and parameters: {'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': 1493, 'alpha': 0.27280628388611244, 'batch_size': 287, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:37:31,118]\u001b[0m Trial 20 finished with value: 0.8109937149651776 and parameters: {'activation': 'tanh', 'solver': 'lbfgs', 'hidden_layer_sizes': 1258, 'alpha': 0.418492993824084, 'batch_size': 234, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:39:42,486]\u001b[0m Trial 21 finished with value: 0.8852644244380274 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1265, 'alpha': 0.06953103273012577, 'batch_size': 273, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:41:52,086]\u001b[0m Trial 22 finished with value: 0.8833596625332654 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1372, 'alpha': 0.06562313252791827, 'batch_size': 300, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:44:02,621]\u001b[0m Trial 23 finished with value: 0.8843126097049996 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1115, 'alpha': 0.08393361622836437, 'batch_size': 266, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:01,581]\u001b[0m Trial 24 finished with value: 0.8785986071003908 and parameters: {'activation': 'tanh', 'solver': 'adam', 'hidden_layer_sizes': 1379, 'alpha': 0.22237507051444852, 'batch_size': 288, 'learning_rate': 'invscaling'}. Best is trial 12 with value: 0.8902652737670573.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_mlp, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_knn(trial):\n",
    "\n",
    "    params = { \n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 16, 200),\n",
    "        }\n",
    "\n",
    "    model = KNeighborsClassifier(**params) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 22:46:42,479]\u001b[0m A new study created in memory with name: no-name-1e04c718-ed05-46bf-908e-04be5aec2405\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:43,440]\u001b[0m Trial 0 finished with value: 0.6146073268784328 and parameters: {'weights': 'uniform', 'n_neighbors': 144}. Best is trial 0 with value: 0.6146073268784328.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:43,647]\u001b[0m Trial 1 finished with value: 0.6634077911783024 and parameters: {'weights': 'distance', 'n_neighbors': 120}. Best is trial 1 with value: 0.6634077911783024.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:43,942]\u001b[0m Trial 2 finished with value: 0.6003252930185154 and parameters: {'weights': 'uniform', 'n_neighbors': 181}. Best is trial 1 with value: 0.6634077911783024.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:44,215]\u001b[0m Trial 3 finished with value: 0.6172263744974804 and parameters: {'weights': 'uniform', 'n_neighbors': 136}. Best is trial 1 with value: 0.6634077911783024.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:44,511]\u001b[0m Trial 4 finished with value: 0.6022297718136006 and parameters: {'weights': 'uniform', 'n_neighbors': 178}. Best is trial 1 with value: 0.6634077911783024.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:44,609]\u001b[0m Trial 5 finished with value: 0.7441036747636034 and parameters: {'weights': 'distance', 'n_neighbors': 16}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:44,821]\u001b[0m Trial 6 finished with value: 0.657456825774305 and parameters: {'weights': 'distance', 'n_neighbors': 135}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,022]\u001b[0m Trial 7 finished with value: 0.684115848479701 and parameters: {'weights': 'uniform', 'n_neighbors': 32}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,244]\u001b[0m Trial 8 finished with value: 0.6569806352981145 and parameters: {'weights': 'distance', 'n_neighbors': 136}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,429]\u001b[0m Trial 9 finished with value: 0.671500764396127 and parameters: {'weights': 'distance', 'n_neighbors': 104}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,555]\u001b[0m Trial 10 finished with value: 0.7145838287752676 and parameters: {'weights': 'distance', 'n_neighbors': 34}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,676]\u001b[0m Trial 11 finished with value: 0.7157748711850971 and parameters: {'weights': 'distance', 'n_neighbors': 33}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,828]\u001b[0m Trial 12 finished with value: 0.6929250891795482 and parameters: {'weights': 'distance', 'n_neighbors': 65}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:45,980]\u001b[0m Trial 13 finished with value: 0.6941161315893778 and parameters: {'weights': 'distance', 'n_neighbors': 64}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,079]\u001b[0m Trial 14 finished with value: 0.7441036747636034 and parameters: {'weights': 'distance', 'n_neighbors': 16}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,180]\u001b[0m Trial 15 finished with value: 0.7400574712643678 and parameters: {'weights': 'distance', 'n_neighbors': 18}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,344]\u001b[0m Trial 16 finished with value: 0.6917360285374554 and parameters: {'weights': 'distance', 'n_neighbors': 68}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,528]\u001b[0m Trial 17 finished with value: 0.6757873280108715 and parameters: {'weights': 'distance', 'n_neighbors': 93}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,668]\u001b[0m Trial 18 finished with value: 0.7045889247494479 and parameters: {'weights': 'distance', 'n_neighbors': 48}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,843]\u001b[0m Trial 19 finished with value: 0.6810228752618764 and parameters: {'weights': 'distance', 'n_neighbors': 87}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:46,952]\u001b[0m Trial 20 finished with value: 0.7374367249872601 and parameters: {'weights': 'distance', 'n_neighbors': 20}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:47,059]\u001b[0m Trial 21 finished with value: 0.7381515769208992 and parameters: {'weights': 'distance', 'n_neighbors': 19}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:47,198]\u001b[0m Trial 22 finished with value: 0.7045889247494479 and parameters: {'weights': 'distance', 'n_neighbors': 48}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:47,301]\u001b[0m Trial 23 finished with value: 0.7398179604778892 and parameters: {'weights': 'distance', 'n_neighbors': 17}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 22:46:47,441]\u001b[0m Trial 24 finished with value: 0.7019701602400771 and parameters: {'weights': 'distance', 'n_neighbors': 49}. Best is trial 5 with value: 0.7441036747636034.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_knn, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dt(trial):\n",
    "    \n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 100),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 5),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 25),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 50, 250),\n",
    "        }\n",
    "    \n",
    "    model = DecisionTreeClassifier(**params, random_state = 22) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-28 19:46:06,019]\u001b[0m A new study created in memory with name: no-name-d8bf2aa8-bbb5-4285-8748-b1255aeae45e\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:08,946]\u001b[0m Trial 0 finished with value: 0.6500787044901195 and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_leaf': 4, 'min_samples_split': 15, 'max_leaf_nodes': 77}. Best is trial 0 with value: 0.6500787044901195.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:15,053]\u001b[0m Trial 1 finished with value: 0.6679332993601721 and parameters: {'criterion': 'entropy', 'max_depth': 93, 'min_samples_leaf': 5, 'min_samples_split': 19, 'max_leaf_nodes': 105}. Best is trial 1 with value: 0.6679332993601721.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:21,249]\u001b[0m Trial 2 finished with value: 0.6674588075420418 and parameters: {'criterion': 'entropy', 'max_depth': 61, 'min_samples_leaf': 4, 'min_samples_split': 21, 'max_leaf_nodes': 207}. Best is trial 1 with value: 0.6679332993601721.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:27,408]\u001b[0m Trial 3 finished with value: 0.6617448049374327 and parameters: {'criterion': 'entropy', 'max_depth': 86, 'min_samples_leaf': 4, 'min_samples_split': 3, 'max_leaf_nodes': 100}. Best is trial 1 with value: 0.6679332993601721.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:33,540]\u001b[0m Trial 4 finished with value: 0.6512700300096257 and parameters: {'criterion': 'entropy', 'max_depth': 82, 'min_samples_leaf': 2, 'min_samples_split': 17, 'max_leaf_nodes': 81}. Best is trial 1 with value: 0.6679332993601721.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:39,696]\u001b[0m Trial 5 finished with value: 0.6705514976501896 and parameters: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 5, 'min_samples_split': 19, 'max_leaf_nodes': 195}. Best is trial 5 with value: 0.6705514976501896.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:42,899]\u001b[0m Trial 6 finished with value: 0.677694354793047 and parameters: {'criterion': 'gini', 'max_depth': 77, 'min_samples_leaf': 2, 'min_samples_split': 8, 'max_leaf_nodes': 229}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:45,861]\u001b[0m Trial 7 finished with value: 0.6557941226431119 and parameters: {'criterion': 'gini', 'max_depth': 34, 'min_samples_leaf': 5, 'min_samples_split': 2, 'max_leaf_nodes': 95}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:48,970]\u001b[0m Trial 8 finished with value: 0.6688862465319063 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_leaf': 3, 'min_samples_split': 20, 'max_leaf_nodes': 155}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:51,810]\u001b[0m Trial 9 finished with value: 0.6355565936243701 and parameters: {'criterion': 'gini', 'max_depth': 33, 'min_samples_leaf': 2, 'min_samples_split': 25, 'max_leaf_nodes': 64}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:54,993]\u001b[0m Trial 10 finished with value: 0.6710285374554101 and parameters: {'criterion': 'gini', 'max_depth': 57, 'min_samples_leaf': 3, 'min_samples_split': 8, 'max_leaf_nodes': 243}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:46:58,174]\u001b[0m Trial 11 finished with value: 0.6686495668421946 and parameters: {'criterion': 'gini', 'max_depth': 65, 'min_samples_leaf': 3, 'min_samples_split': 9, 'max_leaf_nodes': 250}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:01,387]\u001b[0m Trial 12 finished with value: 0.6736478681841345 and parameters: {'criterion': 'gini', 'max_depth': 69, 'min_samples_leaf': 2, 'min_samples_split': 9, 'max_leaf_nodes': 248}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:04,579]\u001b[0m Trial 13 finished with value: 0.6729344317988788 and parameters: {'criterion': 'gini', 'max_depth': 73, 'min_samples_leaf': 2, 'min_samples_split': 9, 'max_leaf_nodes': 205}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:07,741]\u001b[0m Trial 14 finished with value: 0.6693627201177736 and parameters: {'criterion': 'gini', 'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 12, 'max_leaf_nodes': 159}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:10,913]\u001b[0m Trial 15 finished with value: 0.670553762527603 and parameters: {'criterion': 'gini', 'max_depth': 74, 'min_samples_leaf': 3, 'min_samples_split': 6, 'max_leaf_nodes': 225}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:14,081]\u001b[0m Trial 16 finished with value: 0.670552913198573 and parameters: {'criterion': 'gini', 'max_depth': 98, 'min_samples_leaf': 2, 'min_samples_split': 12, 'max_leaf_nodes': 184}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:17,189]\u001b[0m Trial 17 finished with value: 0.668410905384746 and parameters: {'criterion': 'gini', 'max_depth': 51, 'min_samples_leaf': 2, 'min_samples_split': 5, 'max_leaf_nodes': 128}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:20,362]\u001b[0m Trial 18 finished with value: 0.6665069928090142 and parameters: {'criterion': 'gini', 'max_depth': 70, 'min_samples_leaf': 3, 'min_samples_split': 11, 'max_leaf_nodes': 229}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:23,533]\u001b[0m Trial 19 finished with value: 0.6745993998074855 and parameters: {'criterion': 'gini', 'max_depth': 86, 'min_samples_leaf': 2, 'min_samples_split': 6, 'max_leaf_nodes': 179}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:26,678]\u001b[0m Trial 20 finished with value: 0.6736478681841345 and parameters: {'criterion': 'gini', 'max_depth': 84, 'min_samples_leaf': 3, 'min_samples_split': 5, 'max_leaf_nodes': 175}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:29,821]\u001b[0m Trial 21 finished with value: 0.6738859634222296 and parameters: {'criterion': 'gini', 'max_depth': 88, 'min_samples_leaf': 3, 'min_samples_split': 5, 'max_leaf_nodes': 176}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:32,932]\u001b[0m Trial 22 finished with value: 0.6691254742087084 and parameters: {'criterion': 'gini', 'max_depth': 91, 'min_samples_leaf': 2, 'min_samples_split': 7, 'max_leaf_nodes': 133}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:36,074]\u001b[0m Trial 23 finished with value: 0.6743618707887435 and parameters: {'criterion': 'gini', 'max_depth': 79, 'min_samples_leaf': 3, 'min_samples_split': 4, 'max_leaf_nodes': 174}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n",
      "\u001b[32m[I 2022-12-28 19:47:39,193]\u001b[0m Trial 24 finished with value: 0.670316516618538 and parameters: {'criterion': 'gini', 'max_depth': 77, 'min_samples_leaf': 2, 'min_samples_split': 3, 'max_leaf_nodes': 136}. Best is trial 6 with value: 0.677694354793047.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_dt, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "\n",
    "    params = { \n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'solver': trial.suggest_categorical('solver', ['newton-cg', 'sag', 'saga', 'lbfgs']),\n",
    "        'multi_class':'multinomial',\n",
    "        'max_iter': 5000\n",
    "        }\n",
    "    \n",
    "    model = LogisticRegression(**params, random_state = 22) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_lr, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF HYPER-PARAMETER TUNING (RUN FROM HERE)\n",
    "\n",
    "Run from below after setting the correct tuned parameters below to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves': 102, \n",
    "              'max_depth': 55, \n",
    "              'n_estimators': 5239, \n",
    "              'subsample_for_bin': 451297, \n",
    "              'min_data_in_leaf': 179, \n",
    "              'reg_alpha': 10.166085786278504, \n",
    "              'colsample_bytree': 0.24351807574820955, \n",
    "              'learning_rate': 0.9590454530172389, \n",
    "              'boosting_type': 'goss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'criterion': 'entropy', \n",
    "             'max_depth': 15, \n",
    "             'n_estimators': 22984, \n",
    "             'min_samples_leaf': 3, \n",
    "             'min_samples_split': 9, \n",
    "             'max_leaf_nodes': 239, \n",
    "             'random_state': 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'booster': 'gbtree', \n",
    "              'lambda': 7.201651687969849e-08, \n",
    "              'alpha': 2.2495125443474775e-05, \n",
    "              'max_depth': 7, \n",
    "              'eta': 9.307925211476325e-06, \n",
    "              'gamma': 1.7948741419263195e-05, \n",
    "              'grow_policy': 'lossguide'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'criterion': 'gini', \n",
    "             'max_depth': 77, \n",
    "             'min_samples_leaf': 2, \n",
    "             'min_samples_split': 8, \n",
    "             'max_leaf_nodes': 229}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = {'activation': 'tanh', \n",
    "              'solver': 'adam', \n",
    "              'hidden_layer_sizes': 1442, \n",
    "              'alpha': 0.0027099149530944583, \n",
    "              'batch_size': 298, \n",
    "              'learning_rate': 'invscaling',\n",
    "              'max_iter':1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'weights': 'distance', \n",
    "              'n_neighbors': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'multi_class':'multinomial',\n",
    "             'class_weight': None, \n",
    "             'solver': 'saga', \n",
    "             'max_iter':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'dt':DecisionTreeClassifier(**dt_params),\n",
    "          'rf':RandomForestClassifier(**rf_params), \n",
    "          'lgb':lgb.LGBMClassifier(**lgb_params), \n",
    "          'xgb':xgb.XGBClassifier(**xgb_params),\n",
    "          'mlp':MLPClassifier(**mlp_params), \n",
    "          'kn':KNeighborsClassifier(**knn_params),  \n",
    "          'lr':LogisticRegression(**lr_params)\n",
    "         }\n",
    "\n",
    "model_abrv = {'dt':'Decision Tree Classifier', \n",
    "              'rf':'Random Forest Classifier', \n",
    "              'lgb':'LGBM Classifier', \n",
    "              'xgb':'XGB Classifier', \n",
    "              'mlp':'MLP Classifier',\n",
    "              'kn':'K-Nearest Neighbors', \n",
    "              'lr':'Logistic Regression', \n",
    "              'v':'Voting Classifier: MLP, LGB', \n",
    "              'v2':'Voting Classifier 2: KNN, XGB, MLP', \n",
    "              'v3':'Voting Classifier 3: XGB, MLP, RF, LR', \n",
    "              'v4':'Voting Classifier 4: MLP, XGB'\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifiers Hyper-Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_params = {'estimators':[('mlp', models['mlp']), \n",
    "                          ('lgb', models['lgb'])], \n",
    "            'voting':'soft'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_params = {'estimators':[('kn', models['kn']), \n",
    "                           ('xgb', models['xgb']), \n",
    "                           ('mlp', models['mlp'])], \n",
    "             'voting':'soft'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_params = {'estimators':[('xgb', models['xgb']),\n",
    "                           ('mlp', models['mlp']),\n",
    "                           ('rf', models['rf']), \n",
    "                           ('lr', models['lr'])], \n",
    "             'voting':'soft'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_params = {'estimators':[('mlp', models['mlp']), \n",
    "                          ('xgb', models['xgb'])], \n",
    "            'voting':'soft'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['v'] = VotingClassifier(**v_params)\n",
    "models['v2'] = VotingClassifier(**v2_params)\n",
    "models['v3'] = VotingClassifier(**v3_params)\n",
    "models['v4'] = VotingClassifier(**v4_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14, model='clf', save=True):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a seaborn heatmap. \n",
    "    Saves confusion matrix file to jpg file.\"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, ax=ax, fmt=\"d\", cmap=plt.cm.Oranges)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "        \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 \n",
    "    t -= 0.5 \n",
    "    plt.ylim(b, t) \n",
    "    if save == True:\n",
    "        plt.savefig('tuned_' + model_abrv[model] + '_confusion_matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(clf, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, models=models, save=False, print_stat=True, inc_train=False, cv=False):\n",
    "    \"\"\"Trains models and outputs score metrics. Takes an identifier, list of models, and split dataset as inputs and has options for saving model, \n",
    "    printing confusion matrix and classification report and getting cross-validated 5 fold accuracy.\"\"\"\n",
    "    clf_model = models[clf]\n",
    "    clf_model.fit(X_train, y_train)\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    if print_stat == True:\n",
    "        clf_report = pd.DataFrame(classification_report(y_test,y_pred, output_dict=True)).T\n",
    "        clf_report.to_csv('tuned_' + model_abrv[clf] + '_classification_report.csv')\n",
    "        print(model_abrv[clf])\n",
    "        print('\\nTest Stats\\n', classification_report(y_test,y_pred))\n",
    "        print_confusion_matrix(confusion_matrix(y_test, y_pred), unique_labels(y_test, y_pred), model=clf)\n",
    "        if inc_train == True:\n",
    "            print(model_abrv[clf])\n",
    "            print('\\nTrain Stats\\n', classification_report(y_train,clf_model.predict(X_train)))\n",
    "            print_confusion_matrix(confusion_matrix(y_train, clf_model.predict(X_train)), unique_labels(y_test, y_pred), model=clf)\n",
    "    if cv == True:\n",
    "        print(model_abrv[clf] + ' CV Accuracy:',  \n",
    "              np.mean(cross_val_score(clf_model, X_train, y_train, cv=5, scoring='accuracy')))\n",
    "    if save == True:\n",
    "        return clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier CV Accuracy: 0.6765047279316007\n"
     ]
    }
   ],
   "source": [
    "# Training and 5-Fold Cross Validation\n",
    "\n",
    "for key in models.keys():\n",
    "    model(key, cv=True, print_stat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Types\n",
    "\n",
    "print(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results and Metrices\n",
    "\n",
    "for key in models.keys():\n",
    "    model(key, inc_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
